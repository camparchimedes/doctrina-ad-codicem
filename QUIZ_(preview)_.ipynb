{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3AZ/J2s5/UH6GkEKaKQMW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 𝙁𝙤𝙪𝙣𝙙𝙖𝙩𝙞𝙤𝙣𝙖𝙡 𝙆𝙣𝙤𝙬𝙡𝙚𝙙𝙜𝙚/{ᵘⁿᵈᵉʳˢᵗᵃⁿᵈⁱⁿᵍ} in 𝘼𝙄 | 𝙈𝙇 | 𝘿𝙇`QUIZ`|📚 🅿🆁🅴🆅🅸🅴🆆\n",
        "\n",
        "**Aptitude level: Intermediate**\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Question 0.01\n",
        "**What distinguishes Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning?**\n",
        "- A) AI is a subset of ML, which is a subset of Deep Learning, indicating a hierarchy of complexity and capability.\n",
        "- B) ML is a subset of AI focused on algorithms that improve automatically through experience. Deep Learning is a subset of ML using neural networks with many layers.\n",
        "- C) Deep Learning is an independent field from AI and ML, focusing exclusively on computer vision and natural language processing.\n",
        "- D) AI and ML are practically the same, while Deep Learning represents the theoretical underpinnings of both fields.\n",
        "\n",
        "### Question 0.1\n",
        "**Which statement accurately describes the types of machine learning?**\n",
        "- A) In supervised learning, algorithms learn from labeled data, unsupervised learning algorithms infer patterns from unlabeled data, and in reinforcement learning, an agent learns to make decisions by performing actions in an environment.\n",
        "- B) Supervised learning is exclusively used for regression tasks, unsupervised learning for clustering, and reinforcement learning cannot be applied to real-world problems.\n",
        "- C) Unsupervised learning algorithms require human intervention to update the labels in the dataset, while supervised learning does not.\n",
        "- D) Reinforcement learning is a subset of supervised learning, where the model is explicitly given the correct answers for the training data.\n",
        "\n",
        "\n",
        "\n",
        "### Question 1 [Neural Networks]\n",
        "**What is the purpose of the activation function in neural networks?**\n",
        "\n",
        "- A) To normalize the output of each neuron to a range between 0 and 1.\n",
        "- B) To allow the network to learn complex patterns through non-linear transformations.\n",
        "- C) To reduce the dimensionality of the input data.\n",
        "- D) To increase the computational speed of the network.\n",
        "\n",
        "**1.1 Which of the following best describes the purpose of choosing an appropriate network architecture for a given problem?**\n",
        "\n",
        "- A) To select a pre-trained architecture that has achieved high performance on a similar task and fine-tune it for the specific problem.\n",
        "- B) To always design a custom architecture from scratch to ensure optimal performance for the specific task.\n",
        "- C) To choose the architecture with the most layers and parameters to maximize the model's capacity to learn complex patterns.\n",
        "- D) To consider factors such as the size and complexity of the dataset, computational resources available, and the specific requirements of the task when selecting an appropriate architecture.\n",
        "\n",
        "**1.2 What is the impact of different weight initialization schemes on the training process and model performance?**\n",
        "\n",
        "- A) Weight initialization has no significant impact on the training process and final model performance.\n",
        "- B) Initializing all weights to zero allows the model to learn the appropriate values from scratch.\n",
        "- C) Random initialization with appropriate scaling (e.g., Xavier or He initialization) can help improve the convergence speed and stability of the training process.\n",
        "- D) Initializing weights with large random values helps the model explore a wider range of solutions during training.\n",
        "\n",
        "\n",
        "**1.3 What is the role of hyperparameter tuning, and which of these approaches are not recommended? Select all that apply**\n",
        "\n",
        "- A) Hyperparameter tuning is not necessary, as the default hyperparameters provided by libraries are always optimal.\n",
        "- B) Manually trying all possible combinations of hyperparameters is the most effective way to find the best configuration.\n",
        "- C) Using techniques like grid search, random search, or Bayesian optimization to systematically explore the hyperparameter space can help find a good configuration efficiently.\n",
        "- D) Hyperparameter tuning should be done only once at the beginning of a project and never revisited during the model development process.\n",
        "\n",
        "**1.4 What are regularization techniques like L1/L2 regularization and dropout, and why are they used? Select all that apply**\n",
        "\n",
        "- A) Regularization techniques are used to increase the complexity of the model and make it more flexible.\n",
        "- B) L1 regularization adds a penalty term proportional to the absolute value of the weights, while L2 regularization adds a penalty term proportional to the square of the weights.\n",
        "- C) Dropout randomly removes hidden units during training, which helps prevent overfitting by forcing the network to learn more robust features.\n",
        "- D) Regularization techniques are only applicable to linear models and have no effect on deep neural networks.\n",
        "\n",
        "### Question 2\n",
        "**You're optimizing a neural network's weights during training. Which mathematical concept is central to understanding how their adjustment is propagates through the network?**\n",
        "- A) Eigenvalues and eigenvectors, for understanding the stability of the system.\n",
        "- B) Chain rule of calculus, for computing the gradient of loss with respect to the weights.\n",
        "- C) Linear algebra, for efficient computation of transformations within the network.\n",
        "- D) Probability theory, for interpreting the output of the final layer in classification tasks.\n",
        "\n",
        "### Question 3\n",
        "**When debugging a machine learning model in Python, what practice can help identify and fix errors efficiently?**\n",
        "- A) Writing extensive documentation for each function and class to clarify purpose and usage.\n",
        "- B) Implementing unit tests for critical functions to ensure they perform as expected under various conditions.\n",
        "- C) Using print statements to track variable values at different execution points.\n",
        "- D) Relying on integrated development environment (IDE) debugging tools to step through the code.\n",
        "\n",
        "### Question 4 [Datasets]\n",
        "**When preparing your dataset for training, you notice high dimensionality is causing performance issues. Which technique can you apply to address this problem?**\n",
        "- A) Normalization, to ensure all data is on the same scale.\n",
        "- B) Regularization, to penalize larger weights in the model.\n",
        "- C) Principal Component Analysis (PCA), to reduce the dimensionality while preserving as much variance as possible.\n",
        "- D) Data augmentation, to artificially increase the size of your dataset.\n",
        "\n",
        "**4.1 In the context of preparing data for training, what technique is essential for handling missing values in your dataset?**\n",
        "- A) Imputation, filling in missing values with statistical measures like mean, median, or mode, or using a predictive model.\n",
        "- B) Deletion, removing records with missing values.\n",
        "- C) Using algorithms that support missing values.\n",
        "- D) Data binning, grouping data into bins or categories.\n",
        "\n",
        "\n",
        "**4.2 When gathering data for a new machine learning project, what is a crucial factor to ensure the quality and reliability of your dataset?**\n",
        "- A) Prioritizing the quantity of data over the quality to ensure robust model training.\n",
        "- B) Ensuring the data sources are diverse and representative of the problem domain to avoid bias.\n",
        "- C) Focusing exclusively on structured data to simplify preprocessing steps.\n",
        "- D) Using only publicly available data to avoid potential privacy issues.\n",
        "\n",
        "**4.3 What is a common strategy for dealing with outliers in your dataset?**\n",
        "- A) Ignoring outliers, as most machine learning models are robust to them.\n",
        "- B) Removing all outliers without analysis to improve model accuracy.\n",
        "- C) Analyzing outliers and deciding on a case-by-case basis whether to keep, modify, or remove them.\n",
        "- D) Transforming all features to the same scale to minimize the impact of outliers.\n",
        "\n",
        "\n",
        "**4.4 Why is feature engineering an important step in preparing your dataset for training?**\n",
        "- A) It allows the model to train faster by reducing the number of features.\n",
        "- B) It involves creating new features to improve model accuracy and performance.\n",
        "- C) It is only necessary for linear models, not for deep models like neural networks.\n",
        "- D) It simplifies the dataset to a point where model training is no longer necessary.\n",
        "\n",
        "### Question 5\n",
        "**How does transfer learning enhance the process of training a deep learning model on a new task?**\n",
        "- A) By using a model pre-trained on a large dataset, then fine-tuning it on a smaller, specific dataset to leverage learned features.\n",
        "- B) Converting an unsupervised learning problem into a supervised one to improve accuracy.\n",
        "- C) Applying genetic algorithms to optimize the network architecture automatically.\n",
        "- D) Increasing the number of layers in the network to improve its capacity.\n",
        "\n",
        "### Question 6\n",
        "**You're developing a model for loan approval. What approach can help ensure the model's decisions do not discriminate against any group?**\n",
        "- A) Conducting thorough testing across diverse demographic groups to identify and correct biases.\n",
        "- B) Increasing the complexity of the model to make its decision process more comprehensive.\n",
        "- C) Collecting more data from the majority group to improve the model's accuracy.\n",
        "- D) Focusing solely on the model's accuracy metric to guide improvements.\n",
        "\n",
        "### Question 7\n",
        "**In the context of evaluating model performance, why is it important to consider both precision and recall?**\n",
        "- A) To ensure the model performs well on both training and unseen data.\n",
        "- B) Precision and recall balance the model's ability to identify relevant instances accurately and the completeness of the relevant instances it identifies.\n",
        "- C) They are required for calculating the model's training speed and efficiency.\n",
        "- D) These metrics help reduce the computational resources needed for model training.\n",
        "\n",
        "### Question 8\n",
        "**What is a critical consideration for deploying models in a production environment to ensure scalability?**\n",
        "- A) Implementing the most complex algorithms to ensure the highest accuracy.\n",
        "- B) Ensuring the model is trained on the largest dataset available to improve generalization.\n",
        "- C) Designing the deployment architecture to support load balancing and auto-scaling.\n",
        "- D) Deploying the model exclusively in high-security environments to protect sensitive data.\n",
        "\n",
        "### Question 9\n",
        "**How do different loss functions contrast, and when should they be used? Select all that apply**\n",
        "- A) Mean Squared Error (MSE) is suitable for regression tasks, while Binary Cross-Entropy is used for binary classification problems.\n",
        "- B) Categorical Cross-Entropy is appropriate for multi-class classification problems, while Kullback-Leibler Divergence is used for measuring the divergence between two probability distributions, often in scenarios involving model regularization or in variational autoencoders.\n",
        "- C) Hinge Loss is commonly used for classification tasks with support vector machines, while Huber Loss is preferred for regression tasks when the dataset contains many outliers.\n",
        "- D) The choice of loss function depends on the specific task: Mean Squared Error (MSE) for regression, Binary Cross-Entropy for binary classification, and Categorical Cross-Entropy for multi-class classification.\n",
        "\n",
        "\n",
        "### Question 10\n",
        "**What strategies can be employed to improve the robustness of a machine learning model against variations in input data?**\n",
        "- A) Data augmentation, to expose the model to a wider variety of input scenarios during training.\n",
        "- B) Regularization techniques, to prevent the model from becoming too complex and overfitting to the training data.\n",
        "- C) Ensemble methods, to combine multiple models and average out their predictions for better generalization.\n",
        "- D) Feature selection, to remove irrelevant or noisy features that may cause the model to learn spurious patterns.\n",
        "\n",
        "### Question 11\n",
        "**Which approach is considered industry best practice for protecting data privacy in machine learning projects?**\n",
        "- A) Limiting data access to as few individuals as possible.\n",
        "- B) Implementing differential privacy techniques during data collection and model training.\n",
        "- C) Using only publicly available datasets to avoid data privacy concerns.\n",
        "- D) Encrypting all data, disregarding the impact on model performance.\n",
        "\n",
        "### Question 12\n",
        "**Which of the following are examples of linear models in machine learning? Select all that apply.**\n",
        "- A) Linear Regression, which models a straight-line relationship between the dependent and independent variables.\n",
        "- B) Lasso Regression, which includes L1 regularization to encourage sparsity in the model coefficients.\n",
        "- C) K-Nearest Neighbors (KNN), which makes predictions based on the majority vote of the nearest data points.\n",
        "- D) Ridge Regression, which includes L2 regularization to penalize the magnitude of the model coefficients.\n",
        "\n",
        "### Question 13\n",
        "**When comparing linear and non-linear models in machine learning, which of the following statements accurately reflect their differences? Select all that apply.**\n",
        "- A) Linear models assume a constant rate of change between the dependent and independent variables, while non-linear models can represent variable rates of change.\n",
        "- B) Linear models can be transformed into non-linear models by introducing polynomial or interaction terms, which allow them to capture more complex relationships.\n",
        "- C) Non-linear models, such as decision trees and kernel SVMs, inherently capture interactions between features without the need for explicit feature engineering.\n",
        "- D) Linear models typically require less computational resources for training and inference compared to non-linear models, which may involve more complex calculations.\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# (Optional) **Scenario to address real-life problem-solving skills:**\n",
        "\n",
        "*A significant environmental issue is that of golf balls ending up in the sea and being swallowed by dolphins, leading to very serious consequences for them. Your team has been tasked with developing an AI solution to identify and track golf balls in marine environments to better understand the extent of the problem.*\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Which of the following approaches (or combination of) will you consider for developing a solution? If it is not listed here, please explain.**\n",
        "- A) Object Detection with a Pre-trained CNN: Utilize a convolutional neural network (CNN) pre-trained on a large image dataset, then fine-tune it for the specific task of golf ball detection in underwater images.\n",
        "- B) Custom Image Segmentation Model: Develop a custom image segmentation model that can distinguish golf balls from the surrounding marine environment, focusing on the unique shape and color characteristics of the golf balls.\n",
        "- C) Anomaly Detection: Implement an anomaly detection system that identifies golf balls as anomalies within the underwater environment, using unsupervised learning techniques to learn the normal marine environment's patterns.\n",
        "- D) Reinforcement Learning for Drone Navigation: Use reinforcement learning to optimize the path of drones for efficient scanning of the marine environment, focusing on areas more likely to contain golf balls.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "ᴀʟʟ ᴛʜᴇ ʙᴇsᴛ,\n",
        "<br>\n",
        "𝙑𝙞𝙘𝙩𝙤𝙧 𝙇𝙚𝙨𝙩𝙖𝙩\n",
        "\n"
      ],
      "metadata": {
        "id": "UbwUKTWqKQ7g"
      }
    }
  ]
}